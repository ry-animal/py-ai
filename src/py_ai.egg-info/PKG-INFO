Metadata-Version: 2.4
Name: py-ai
Version: 0.1.0
Summary: Python AI learning project
Requires-Python: >=3.11
Description-Content-Type: text/markdown
Requires-Dist: fastapi>=0.115.0
Requires-Dist: uvicorn[standard]>=0.30.0
Requires-Dist: pydantic-settings>=2.4.0
Requires-Dist: openai>=1.43.0
Requires-Dist: httpx>=0.27.0
Requires-Dist: instructor>=1.3.0
Requires-Dist: anthropic>=0.34.0
Requires-Dist: chromadb>=0.5.4
Requires-Dist: sentence-transformers>=3.0.1
Requires-Dist: email-validator>=2.0.0
Requires-Dist: pytest>=8.2.0
Requires-Dist: requests>=2.32.0
Requires-Dist: ragas>=0.1.6
Requires-Dist: datasets>=2.19.0
Requires-Dist: langchain>=0.2.0
Requires-Dist: langgraph>=0.2.30
Requires-Dist: celery[redis]>=5.4.0
Requires-Dist: opentelemetry-api>=1.20.0
Requires-Dist: opentelemetry-sdk>=1.20.0
Requires-Dist: opentelemetry-instrumentation-fastapi>=0.41b0
Requires-Dist: opentelemetry-instrumentation-httpx>=0.41b0
Requires-Dist: opentelemetry-exporter-otlp>=1.20.0
Requires-Dist: python-multipart>=0.0.6
Requires-Dist: pypdf>=4.3.0
Provides-Extra: dev
Requires-Dist: pytest>=8.2.0; extra == "dev"
Requires-Dist: ruff>=0.6.9; extra == "dev"
Requires-Dist: pre-commit>=3.8.0; extra == "dev"
Provides-Extra: agent
Requires-Dist: redis>=5.0.0; extra == "agent"

# Doc-QA Assistant - Python AI Backend Capstone

A production-ready document Q&A assistant that intelligently routes queries between internal documents and web search, providing cited responses with conversation continuity. Built as the capstone project for a comprehensive Python AI backend development learning journey.

## üéØ Capstone Features

### üìÑ Document Management
- **File Upload API**: PDF, TXT, MD support with validation and size limits
- **Background Processing**: Async document ingestion via Celery workers
- **Text Extraction**: PDF parsing with metadata preservation
- **Smart Chunking**: Recursive text splitting with overlap for optimal retrieval

### üß† Intelligent Agent System
- **LangGraph Workflow**: Explicit routing between RAG and web search
- **Smart Routing**: Prefers internal docs (relevance > 0.7) unless web intent detected
- **Citation Support**: Links answers back to source documents with relevance scores
- **Session Management**: Redis-backed conversation history with 24h TTL

### üöÄ Production-Ready Infrastructure  
- **FastAPI Backend**: Type-safe endpoints with OpenAPI documentation
- **Multi-Provider AI**: OpenAI primary, Anthropic fallback with graceful degradation
- **Observability**: OpenTelemetry traces, structured logging, health checks
- **Security**: Rate limiting, input validation, automated security scanning
- **Containerization**: Multi-stage Docker builds with health checks

## Quickstart
1) Prereqs: Python 3.11+, `uv` installed
2) Install
```bash
make setup   # uv sync + pre-commit hooks
```
3) Environment (.env)
```ini
ANTHROPIC_API_KEY=...
# Optional
OPENAI_API_KEY=...
TAVILY_API_KEY=...
STREAMING_ENABLED=true
MODEL_NAME=gpt-4o-mini
CLAUDE_MODEL=claude-3-5-sonnet-latest
embedding_model=all-MiniLM-L6-v2
MAX_WEB_RESULTS=10
TAVILY_SEARCH_DEPTH=advanced
REDIS_URL=redis://localhost:6379/0
CELERY_BROKER_URL=redis://localhost:6379/1
CELERY_RESULT_BACKEND=redis://localhost:6379/2
CELERY_TASK_DEFAULT_QUEUE=default
MAX_REQUEST_BODY_BYTES=2000000
RATE_LIMIT_REQUESTS_PER_WINDOW=120
RATE_LIMIT_WINDOW_SECONDS=60
```
4) Run
```bash
# Local development
make run        # http://127.0.0.1:8000/docs (binds 0.0.0.0)
make worker     # start Celery worker (requires Redis)

# Or with Docker (recommended)
docker compose up --build  # http://127.0.0.1:8010/docs
```

## üé¨ Demo the Capstone

Run the complete demonstration that showcases all features:

```bash
python demo_capstone.py
```

This demonstrates:
- Document upload and processing
- Intelligent routing between internal docs and web search  
- Citation support with source tracking
- Session-based conversation continuity
- Performance monitoring and evaluation

## üîó Key Endpoints

### Document Management
- **POST** `/docs/upload` - Upload PDF, TXT, MD files with async processing
- **GET** `/docs/` - List all uploaded documents  
- **GET** `/docs/{doc_id}` - Get document details
- **DELETE** `/docs/{doc_id}` - Remove document and cleanup

### Intelligent Chat
- **POST** `/chat/` - Send message and get AI response with citations
- **GET** `/chat/stream` - Stream chat responses in real-time
- **GET** `/chat/sessions/{session_id}/history` - Get conversation history
- **DELETE** `/chat/sessions/{session_id}` - Clear chat session

### Legacy Endpoints (still available)
- **GET** `/health`, `/ready` - System health checks
- **POST** `/extract-user` - Structured data extraction
- **POST** `/rag/reload` - Direct RAG document loading
- **GET** `/ask` - Basic Q&A without citations
- **GET** `/agent/chat` - Agent chat without enhanced features

## üìö Usage Examples

### Document Upload & Chat
```bash
# Upload a document (using Docker port 8010)
curl -X POST http://127.0.0.1:8010/docs/upload \
  -F "file=@demo_docs/company_handbook.md"

# Chat with citations
curl -X POST http://127.0.0.1:8010/chat/ \
  -H "Content-Type: application/json" \
  -d '{"message": "What are the company core values?"}'

# Stream chat response  
curl -N http://127.0.0.1:8010/chat/stream?q=What%20benefits%20do%20employees%20get

# Get conversation history
curl http://127.0.0.1:8010/chat/sessions/demo_session/history
```

### Legacy RAG API
```bash
# Direct document loading
curl -X POST http://127.0.0.1:8010/rag/reload \
  -H 'Content-Type: application/json' \
  -d '[["1","FastAPI is a modern web framework."]]'

# Basic Q&A
curl "http://127.0.0.1:8010/ask?q=What%20is%20FastAPI&stream=true"
```

## Dev commands
```bash
make run       # start API
make test      # run tests
make lint      # ruff check
make format    # ruff format
make eval      # RAG simple eval ‚Üí portfolio/eval_report.csv
make weval     # Web agent eval ‚Üí portfolio/web_eval_report.csv
make ragas     # RAGAS metrics ‚Üí portfolio/ragas_report.csv
make agent-eval # Blended agent eval ‚Üí portfolio/agent_eval_report.csv
make worker    # Celery worker (background jobs)
```

Set `API_BASE_URL` when running against Docker compose (e.g. `make eval API_BASE_URL=http://127.0.0.1:8010`).

## üê≥ Docker Deployment

```bash
# Production deployment (recommended)
docker compose up --build  # API on http://127.0.0.1:8010

# Or build individual images
docker build --target prod -t py-ai:latest .
docker build --target worker -t py-ai-worker:latest .
```

The Docker setup includes:
- **Multi-stage builds**: Optimized for production with non-root users
- **Health checks**: Built-in monitoring for orchestration
- **Service dependencies**: Redis, API, and worker with proper startup order
- **Volume mounts**: Persistent storage for documents and evaluation reports

## üìã Architecture & Documentation

- **[ARCHITECTURE.md](ARCHITECTURE.md)**: Complete system design and data flow
- **[PORTFOLIO.md](PORTFOLIO.md)**: Executive summary and achievements  
- **[CAPSTONE.md](CAPSTONE.md)**: Project specification and requirements
- **[LEARNINGS.md](LEARNINGS.md)**: Technical insights and best practices
- **[CHECKPOINT.md](CHECKPOINT.md)**: Development progress and milestones

## üéì Learning Journey

This project represents the capstone of an 8-week Python AI backend development study plan:

1. **Phase 0-1**: Environment setup and Python fluency
2. **Phase 2**: FastAPI backend with typed endpoints  
3. **Phase 3**: Structured AI output with Instructor
4. **Phase 4**: RAG pipeline with vector database
5. **Phase 5**: Agent system with LangGraph
6. **Phase 6**: Production deployment and observability
7. **Capstone**: Complete Doc-QA Assistant with citations

## üìä Evaluation & Metrics

The system includes comprehensive evaluation harnesses:

```bash
make eval       # Basic RAG evaluation
make ragas      # Semantic evaluation metrics  
make agent-eval # Agent routing accuracy
make weval      # Web search quality
```

Reports are generated in `portfolio/` for tracking performance over time.

---

**Built with**: FastAPI, LangGraph, ChromaDB, OpenTelemetry, Docker, Redis, Celery  
**Demonstrates**: Production-ready Python AI backend development from design to deployment
