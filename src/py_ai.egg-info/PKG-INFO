Metadata-Version: 2.4
Name: py-ai
Version: 0.1.0
Summary: Python AI learning project
Requires-Python: >=3.11
Description-Content-Type: text/markdown
Requires-Dist: fastapi>=0.115.0
Requires-Dist: uvicorn[standard]>=0.30.0
Requires-Dist: pydantic-settings>=2.4.0
Requires-Dist: openai>=1.43.0
Requires-Dist: httpx>=0.27.0
Requires-Dist: instructor>=1.3.0
Requires-Dist: anthropic>=0.34.0
Requires-Dist: chromadb>=0.5.4
Requires-Dist: sentence-transformers>=3.0.1
Requires-Dist: email-validator>=2.0.0
Requires-Dist: pytest>=8.2.0
Requires-Dist: requests>=2.32.0
Requires-Dist: ragas>=0.1.6
Requires-Dist: datasets>=2.19.0
Requires-Dist: langchain>=0.2.0
Requires-Dist: langgraph>=0.2.30
Requires-Dist: celery[redis]>=5.4.0
Requires-Dist: opentelemetry-api>=1.20.0
Requires-Dist: opentelemetry-sdk>=1.20.0
Requires-Dist: opentelemetry-instrumentation-fastapi>=0.41b0
Requires-Dist: opentelemetry-instrumentation-httpx>=0.41b0
Requires-Dist: opentelemetry-exporter-otlp>=1.20.0
Requires-Dist: python-multipart>=0.0.6
Requires-Dist: pypdf>=4.3.0
Requires-Dist: pydantic-ai>=1.9.0
Requires-Dist: ag-ui-protocol>=0.1.9
Requires-Dist: motor>=3.5.0
Requires-Dist: asyncpg>=0.29.0
Requires-Dist: redis>=5.0.0
Provides-Extra: dev
Requires-Dist: pytest>=8.2.0; extra == "dev"
Requires-Dist: ruff>=0.6.9; extra == "dev"
Requires-Dist: pre-commit>=3.8.0; extra == "dev"
Provides-Extra: agent
Requires-Dist: redis>=5.0.0; extra == "agent"
Provides-Extra: vertex
Requires-Dist: google-cloud-aiplatform>=1.40.0; extra == "vertex"
Requires-Dist: google-cloud-storage>=2.10.0; extra == "vertex"
Provides-Extra: snowflake
Requires-Dist: snowflake-connector-python>=3.0.0; extra == "snowflake"
Provides-Extra: cockroach
Requires-Dist: asyncpg>=0.29.0; extra == "cockroach"
Requires-Dist: psycopg2-binary>=2.9.0; extra == "cockroach"
Provides-Extra: enterprise
Requires-Dist: google-cloud-aiplatform>=1.40.0; extra == "enterprise"
Requires-Dist: snowflake-connector-python>=3.0.0; extra == "enterprise"
Requires-Dist: psycopg2-binary>=2.9.0; extra == "enterprise"
Requires-Dist: prometheus-client>=0.19.0; extra == "enterprise"
Requires-Dist: structlog>=23.2.0; extra == "enterprise"
Provides-Extra: all
Requires-Dist: google-cloud-aiplatform>=1.40.0; extra == "all"
Requires-Dist: snowflake-connector-python>=3.0.0; extra == "all"
Requires-Dist: psycopg2-binary>=2.9.0; extra == "all"
Requires-Dist: prometheus-client>=0.19.0; extra == "all"
Requires-Dist: structlog>=23.2.0; extra == "all"
Requires-Dist: pytest>=8.2.0; extra == "all"
Requires-Dist: ruff>=0.6.9; extra == "all"
Requires-Dist: pre-commit>=3.8.0; extra == "all"

# Doc-QA Assistant - Python AI Backend Capstone

A production-ready document Q&A assistant that intelligently routes queries between internal documents and web search, providing cited responses with conversation continuity. Built as the capstone project for a comprehensive Python AI backend development learning journey.

## üéØ Capstone Features

### üìÑ Document Management
- **File Upload API**: PDF, TXT, MD support with validation and size limits
- **Background Processing**: Async document ingestion via Celery workers
- **Text Extraction**: PDF parsing with metadata preservation
- **Smart Chunking**: Recursive text splitting with overlap for optimal retrieval

### üß† Multi-Agent AI System
- **Four Agent Architectures**: LangGraph, Pydantic-AI, Hybrid, and Smart Orchestrator
- **Intelligent Routing**: Task-aware agent selection with fallback mechanisms
- **Type-Safe Operations**: Structured output validation and modern patterns
- **Smart Routing**: Prefers internal docs (relevance > 0.7) unless web intent detected
- **Citation Support**: Links answers back to source documents with relevance scores
- **Session Management**: Redis-backed conversation history with 24h TTL

### üöÄ Production-Ready Infrastructure  
- **FastAPI Backend**: Type-safe endpoints with OpenAPI documentation
- **Multi-Provider AI**: OpenAI primary, Anthropic fallback with graceful degradation
- **Observability**: OpenTelemetry traces, structured logging, health checks
- **Security**: Rate limiting, input validation, automated security scanning
- **Containerization**: Multi-stage Docker builds with health checks

## Quickstart
1) Prereqs: Python 3.11+, `uv` installed
2) Install
```bash
make setup   # uv sync + pre-commit hooks
```
3) Environment (.env)
```ini
ANTHROPIC_API_KEY=...
# Optional
OPENAI_API_KEY=...
TAVILY_API_KEY=...
STREAMING_ENABLED=true
MODEL_NAME=gpt-4o-mini
CLAUDE_MODEL=claude-3-5-sonnet-latest
embedding_model=all-MiniLM-L6-v2
MAX_WEB_RESULTS=10
TAVILY_SEARCH_DEPTH=advanced
REDIS_URL=redis://localhost:6379/0
CELERY_BROKER_URL=redis://localhost:6379/1
CELERY_RESULT_BACKEND=redis://localhost:6379/2
CELERY_TASK_DEFAULT_QUEUE=default
MAX_REQUEST_BODY_BYTES=2000000
RATE_LIMIT_REQUESTS_PER_WINDOW=120
RATE_LIMIT_WINDOW_SECONDS=60
```
4) Run
```bash
# Local development
make run        # http://127.0.0.1:8000/docs (binds 0.0.0.0)
make worker     # start Celery worker (requires Redis)

# Or with Docker (recommended)
docker compose up --build  # http://127.0.0.1:8010/docs
```

## üé¨ Demo the Capstone

Run the complete demonstration that showcases all features:

```bash
python demo_capstone.py
```

This demonstrates:
- Document upload and processing
- Intelligent routing between internal docs and web search  
- Citation support with source tracking
- Session-based conversation continuity
- Performance monitoring and evaluation

## üîó Key Endpoints

### Document Management
- **POST** `/docs/upload` - Upload PDF, TXT, MD files with async processing
- **GET** `/docs/` - List all uploaded documents  
- **GET** `/docs/{doc_id}` - Get document details
- **DELETE** `/docs/{doc_id}` - Remove document and cleanup

### Multi-Agent Chat System

#### üéØ Smart Orchestrator (Recommended)
- **POST/GET** `/smart/chat` - Intelligent agent selection based on task analysis
- **POST** `/smart/analyze` - Preview agent selection without execution
- **GET** `/smart/status` - Orchestrator status and capabilities
- **GET** `/smart/agents/comparison` - Compare all available agents

#### üî¨ LangGraph Agent (Complex Workflows)
- **POST/GET** `/agent/chat` - Complex multi-step workflows with state management
- **GET** `/agent/status` - LangGraph agent status and capabilities

#### üèóÔ∏è Pydantic-AI Agent (Type-Safe & Structured)
- **POST/GET** `/pydantic-agent/chat` - Type-safe operations with structured output
- **GET** `/pydantic-agent/status` - Pydantic-AI agent status
- **GET** `/pydantic-agent/ag-ui` - AG-UI protocol compatibility endpoint

#### ‚ö° Hybrid Agent (Best of Both Worlds)
- **POST/GET** `/hybrid-agent/chat` - LangGraph workflows + Pydantic-AI tools
- **GET** `/hybrid-agent/status` - Hybrid agent status and architecture
- **GET** `/hybrid-agent/architecture` - Detailed integration patterns

### Enhanced Chat Interface
- **POST** `/chat/` - Send message and get AI response with citations
- **GET** `/chat/stream` - Stream chat responses in real-time
- **GET** `/chat/sessions/{session_id}/history` - Get conversation history
- **DELETE** `/chat/sessions/{session_id}` - Clear chat session

### System Endpoints
- **GET** `/health`, `/ready` - System health checks
- **POST** `/extract-user` - Structured data extraction
- **POST** `/rag/reload` - Direct RAG document loading
- **GET** `/ask` - Basic Q&A without citations

## üìö Usage Examples

### Document Upload & Enhanced Chat
```bash
# Upload a document (using Docker port 8010)
curl -X POST http://127.0.0.1:8010/docs/upload \
  -F "file=@demo_docs/company_handbook.md"

# Enhanced chat with citations
curl -X POST http://127.0.0.1:8010/chat/ \
  -H "Content-Type: application/json" \
  -d '{"message": "What are the company core values?"}'

# Stream chat response  
curl -N http://127.0.0.1:8010/chat/stream?q=What%20benefits%20do%20employees%20get

# Get conversation history
curl http://127.0.0.1:8010/chat/sessions/demo_session/history
```

### Multi-Agent System Usage

#### Smart Orchestrator (Automatic Selection)
```bash
# Let the orchestrator choose the best agent
curl "http://127.0.0.1:8010/smart/chat?q=What%20is%20Python?"

# Analyze task without execution
curl -X POST http://127.0.0.1:8010/smart/analyze \
  -H "Content-Type: application/json" \
  -d '{"question": "Extract user data in JSON format"}'

# Compare all available agents
curl http://127.0.0.1:8010/smart/agents/comparison

# Force specific agent for testing
curl -X POST http://127.0.0.1:8010/smart/chat \
  -H "Content-Type: application/json" \
  -d '{"question": "Hello", "force_agent": "pydantic_ai"}'
```

#### Individual Agent Usage
```bash
# LangGraph Agent (complex workflows)
curl "http://127.0.0.1:8010/agent/chat?q=Analyze%20and%20create%20a%20step-by-step%20plan"

# Pydantic-AI Agent (structured output)
curl "http://127.0.0.1:8010/pydantic-agent/chat?q=What%20is%20FastAPI?"

# Hybrid Agent (workflow + type safety)
curl "http://127.0.0.1:8010/hybrid-agent/chat?q=Search%20docs%20and%20format%20results"

# Check agent status
curl http://127.0.0.1:8010/pydantic-agent/status
curl http://127.0.0.1:8010/hybrid-agent/status
```

#### Testing All Agents
```bash
# Test all agent architectures
make test-all-agents

# Get agent status summary
make agent-status

# Run integration demo
make demo-integration
```

### Legacy RAG API
```bash
# Direct document loading
curl -X POST http://127.0.0.1:8010/rag/reload \
  -H 'Content-Type: application/json' \
  -d '[["1","FastAPI is a modern web framework."]]'

# Basic Q&A
curl "http://127.0.0.1:8010/ask?q=What%20is%20FastAPI&stream=true"
```

## Dev commands
```bash
# Core Development
make run           # start API
make test          # run tests
make lint          # ruff check
make format        # ruff format
make worker        # Celery worker (background jobs)
make setup         # install dependencies and pre-commit hooks

# Development Workflow Testing
source scripts/py-dev-workflow.sh  # comprehensive workflow validation
# Runs: health check ‚Üí agent availability ‚Üí smart routing ‚Üí chat functionality

# Multi-Agent Testing
make test-all-agents    # test all 4 agent architectures
make test-hybrid        # test hybrid agent specifically
make test-smart         # test smart orchestrator
make agent-status       # get status summary of all agents
make demo-integration   # comprehensive multi-agent demo

# Evaluation & Metrics
make eval          # RAG simple eval ‚Üí portfolio/eval_report.csv
make weval         # Web agent eval ‚Üí portfolio/web_eval_report.csv
make ragas         # RAGAS metrics ‚Üí portfolio/ragas_report.csv
make agent-eval    # Blended agent eval ‚Üí portfolio/agent_eval_report.csv
make compare-agents # Compare agent performance
```

Set `API_BASE_URL` when running against Docker compose (e.g. `make eval API_BASE_URL=http://127.0.0.1:8010`).

## üê≥ Docker Deployment

```bash
# Production deployment (recommended)
docker compose up --build  # API on http://127.0.0.1:8010

# Or build individual images
docker build --target prod -t py-ai:latest .
docker build --target worker -t py-ai-worker:latest .
```

The Docker setup includes:
- **Multi-stage builds**: Optimized for production with non-root users
- **Health checks**: Built-in monitoring for orchestration
- **Service dependencies**: Redis, API, and worker with proper startup order
- **Volume mounts**: Persistent storage for documents and evaluation reports

## üè¢ Enterprise Deployment

### Quick Enterprise Setup

```bash
# 1. Setup enterprise dependencies
uv add --group enterprise

# 2. Configure enterprise environment
cp .env.enterprise.example .env
# Edit .env with your database URLs and API keys

# 3. Choose your vector database
export VECTOR_DB_TYPE=vertex     # or snowflake, cockroach
export GCP_PROJECT_ID=your-project-id

# 4. Deploy with Terraform
cd terraform/environments/staging
terraform init
terraform plan
terraform apply
```

### Enterprise Features

**üéØ Multi-Cloud Vector Databases**
- **Vertex AI**: Production-ready with auto-scaling
- **Snowflake Cortex**: Data warehouse + vectors 
- **CockroachDB**: SQL + vectors (Bonus! üéØ)
- **ChromaDB**: Local development fallback

**üîÑ Harness CI/CD Pipeline**
- Multi-agent testing automation
- Security scanning (containers + dependencies)
- Blue-green production deployment
- Automatic rollback on failure

**üìä Enterprise Observability**
- OpenTelemetry distributed tracing
- PostgreSQL metrics and audit logging
- MongoDB document analytics
- Agent performance dashboards

**üîê Production Security**
- Container vulnerability scanning
- Dependency security analysis
- Rate limiting and request validation
- Secret management integration

### Database Configuration

```bash
# Enterprise Database Stack
MONGODB_URL=mongodb+srv://cluster/py_ai_platform
POSTGRES_URL=postgresql://host:5432/py_ai_metadata
REDIS_URL=redis://cluster:6379/0

# Vector Database (choose one)
VECTOR_DB_TYPE=vertex
GCP_PROJECT_ID=your-project-id
VERTEX_INDEX_ENDPOINT_ID=your-endpoint

# Or Snowflake
VECTOR_DB_TYPE=snowflake
SNOWFLAKE_ACCOUNT=your-account.snowflakecomputing.com

# Or CockroachDB (Bonus!)
VECTOR_DB_TYPE=cockroach
COCKROACH_CONNECTION_STRING=postgresql://host:26257/db
```

### Deployment Validation

```bash
# Verify enterprise deployment
terraform output  # Get deployment URLs

# Test all agent architectures
curl "https://your-api/smart/chat?q=Hello"
curl "https://your-api/agent/chat?q=Hello"
curl "https://your-api/pydantic-agent/chat?q=Hello"
curl "https://your-api/hybrid-agent/chat?q=Hello"

# Check enterprise features
curl https://your-api/smart/agents/comparison
curl https://your-api/metrics
```

See **[DEPLOYMENT_GUIDE.md](DEPLOYMENT_GUIDE.md)** for complete enterprise setup instructions.

### Enterprise Testing

**Automated Testing**
```bash
# Run all enterprise tests
uv run pytest tests/test_enterprise_database.py -v
uv run pytest tests/test_enterprise_integration.py -v

# Test database connections
make test-databases

# Validate full enterprise deployment
make validate-enterprise
```

**Manual Testing**
```bash
# Follow comprehensive manual testing procedures
# See MANUAL_TESTING_GUIDE.md for detailed steps

# Quick validation of all agent architectures
make test-all-agents
make agent-status
make demo-integration
```

**Performance Testing**
```bash
# Test concurrent requests and response times
# Load testing procedures in MANUAL_TESTING_GUIDE.md

# Memory usage monitoring
# Benchmark procedures documented in testing guide
```

## ü§ñ Multi-Agent Architecture

The system provides **four distinct agent architectures**, each optimized for different use cases:

### Agent Selection Guide

| Use Case | Recommended Agent | Why? |
|----------|------------------|------|
| **Simple Q&A** | üéØ Smart Orchestrator | Auto-routes to optimal agent |
| **Complex Workflows** | üî¨ LangGraph Agent | Advanced state management |
| **Structured Output** | üèóÔ∏è Pydantic-AI Agent | Type safety & validation |
| **Mixed Requirements** | ‚ö° Hybrid Agent | Best of both worlds |
| **General Purpose** | üéØ Smart Orchestrator | Task-aware routing |

### Architecture Benefits

1. **üéØ Smart Orchestrator**: Automatically chooses the best agent based on task analysis
   - **Strengths**: Intelligent routing, fallback mechanisms, simplified interface
   - **Best For**: General-purpose applications, varied workloads, user-facing systems

2. **üî¨ LangGraph Agent**: Complex multi-step workflows with state management
   - **Strengths**: Advanced workflows, conditional logic, mature ecosystem
   - **Best For**: Multi-agent coordination, state-dependent processing

3. **üèóÔ∏è Pydantic-AI Agent**: Type-safe operations with structured output
   - **Strengths**: Type safety, structured validation, modern patterns, AG-UI ready
   - **Best For**: Structured responses, frontend integrations, developer experience

4. **‚ö° Hybrid Agent**: LangGraph workflows with Pydantic-AI tools
   - **Strengths**: Complex workflows + type safety, migration-friendly
   - **Best For**: Production systems, enterprise applications, gradual migrations

### Migration Strategy

- **Start with**: Smart Orchestrator for automatic routing
- **Specialize**: Use specific agents for performance-critical paths
- **Migrate**: Gradually move from LangGraph to modern patterns via Hybrid
- **Scale**: Type-safe operations with Pydantic-AI for new features

## üìã Architecture & Documentation

- **[ARCHITECTURE.md](docs/ARCHITECTURE.md)**: Complete system design and data flow
- **[PORTFOLIO.md](docs/PORTFOLIO.md)**: Executive summary and achievements  
- **[CAPSTONE.md](docs/CAPSTONE.md)**: Project specification and requirements
- **[LEARNINGS.md](docs/LEARNINGS.md)**: Technical insights and best practices
- **[CHECKPOINT.md](docs/CHECKPOINT.md)**: Development progress and milestones

## üìä Evaluation & Metrics

The system includes comprehensive evaluation harnesses:

```bash
make eval       # Basic RAG evaluation
make ragas      # Semantic evaluation metrics  
make agent-eval # Agent routing accuracy
make weval      # Web search quality
```

Reports are generated in `portfolio/` for tracking performance over time.

---

**Built with**: FastAPI, LangGraph, ChromaDB, OpenTelemetry, Docker, Redis, Celery  
**Demonstrates**: Production-ready Python AI backend development from design to deployment
